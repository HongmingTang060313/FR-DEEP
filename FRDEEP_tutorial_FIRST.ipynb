{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This script mostly follows [the standard CIFAR10 Pytorch example](https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html). It extracts grey scale images from the dataset.\n",
    "\n",
    "The steps are:\n",
    "\n",
    "1. Load and normalizing the FRDEEP-F training and test datasets using torchvision\n",
    "2. Define a Convolutional Neural Network\n",
    "3. Define a loss function\n",
    "4. Train the network on the training data\n",
    "5. Test the network on the test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First import some standard python libraries for plotting stuff and handling arrays:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then import the pytorch, torchvision and torchsummary libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then import the pytorch neural network stuff:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then import the oprimization library from pytorch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally import the FRDEEP-F pytorch dataset class. This is not provided with pytorch, you need to [grab it from the FRDEEP github](\n",
    "https://github.com/HongmingTang060313/FR-DEEP/blob/master/FRDEEP.py)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from FRDEEP import FRDEEPF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output of torchvision datasets are PILImage images of range [0, 1]. We transform them to Tensors of normalized range [-1, 1]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize([0.5],[0.5])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load in the training and test datasets. The first time you do this it will download the data to your working directory, but once the data is there it will just use it without repeating the download."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/306842 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://www.jb.man.ac.uk/research/ascaife/FIRST_PNG_dataset.tar.gz to ./FIRST_data/FIRST_PNG_dataset.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "311296it [00:00, 365177.65it/s]                            \n"
     ]
    }
   ],
   "source": [
    "trainset = FRDEEPF(root='./FIRST_data', train=True, download=True, transform=transform)  \n",
    "batch_size_train = 2\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size_train, shuffle=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "testset = FRDEEPF(root='./FIRST_data', train=False, download=True, transform=transform) \n",
    "batch_size_test = 2\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size_test, shuffle=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two classes in this dataset: FRI and FRII:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ('FRI', 'FRII')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A little function to display images nicely:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(img):\n",
    "    # unnormalize\n",
    "    img = img / 2 + 0.5\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take a look at some randomly selected samples to see how they appear:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get some random training images\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  FRI   FRI\n"
     ]
    }
   ],
   "source": [
    "# show images\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "# print labels\n",
    "print(' '.join('%5s' % classes[labels[j]] for j in range(batch_size_train)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a neural network that takes greyscale images as input:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 34 * 34, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # conv1 output width: input_width - (kernel_size - 1) => 150 - (5-1) = 146\n",
    "        # pool 1 output width: int(input_width/2) => 73\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        # conv2 output width: input_width - (kernel_size - 1) => 73 - (5-1) = 69\n",
    "        # pool 2 output width: int(input_width/2) => 34\n",
    "        x = self.pool(F.relu(self.conv2(x)))  \n",
    "        x = x.view(-1, 16 * 34 * 34)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 6, 146, 146]             156\n",
      "         MaxPool2d-2            [-1, 6, 73, 73]               0\n",
      "            Conv2d-3           [-1, 16, 69, 69]           2,416\n",
      "         MaxPool2d-4           [-1, 16, 34, 34]               0\n",
      "            Linear-5                  [-1, 120]       2,219,640\n",
      "            Linear-6                   [-1, 84]          10,164\n",
      "            Linear-7                   [-1, 10]             850\n",
      "================================================================\n",
      "Total params: 2,233,226\n",
      "Trainable params: 2,233,226\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.09\n",
      "Forward/backward pass size (MB): 1.94\n",
      "Params size (MB): 8.52\n",
      "Estimated Total Size (MB): 10.55\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "net = Net()\n",
    "summary(net,(1,150,150))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll use Classification Cross-Entropy loss and Adagrad with momentum for optimization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adagrad(net.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run 10 epochs of training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,    50] loss: 1.324\n",
      "[1,   100] loss: 0.704\n",
      "[1,   150] loss: 0.715\n",
      "[1,   200] loss: 0.782\n",
      "[1,   250] loss: 0.732\n",
      "[2,    50] loss: 0.683\n",
      "[2,   100] loss: 0.664\n",
      "[2,   150] loss: 0.678\n",
      "[2,   200] loss: 0.666\n",
      "[2,   250] loss: 0.605\n",
      "[3,    50] loss: 0.624\n",
      "[3,   100] loss: 0.508\n",
      "[3,   150] loss: 0.640\n",
      "[3,   200] loss: 0.562\n",
      "[3,   250] loss: 0.513\n",
      "[4,    50] loss: 0.493\n",
      "[4,   100] loss: 0.517\n",
      "[4,   150] loss: 0.478\n",
      "[4,   200] loss: 0.494\n",
      "[4,   250] loss: 0.492\n",
      "[5,    50] loss: 0.427\n",
      "[5,   100] loss: 0.433\n",
      "[5,   150] loss: 0.442\n",
      "[5,   200] loss: 0.434\n",
      "[5,   250] loss: 0.443\n",
      "[6,    50] loss: 0.411\n",
      "[6,   100] loss: 0.296\n",
      "[6,   150] loss: 0.311\n",
      "[6,   200] loss: 0.424\n",
      "[6,   250] loss: 0.367\n",
      "[7,    50] loss: 0.312\n",
      "[7,   100] loss: 0.324\n",
      "[7,   150] loss: 0.277\n",
      "[7,   200] loss: 0.369\n",
      "[7,   250] loss: 0.325\n",
      "[8,    50] loss: 0.357\n",
      "[8,   100] loss: 0.278\n",
      "[8,   150] loss: 0.255\n",
      "[8,   200] loss: 0.279\n",
      "[8,   250] loss: 0.241\n",
      "[9,    50] loss: 0.258\n",
      "[9,   100] loss: 0.250\n",
      "[9,   150] loss: 0.223\n",
      "[9,   200] loss: 0.188\n",
      "[9,   250] loss: 0.280\n",
      "[10,    50] loss: 0.171\n",
      "[10,   100] loss: 0.323\n",
      "[10,   150] loss: 0.175\n",
      "[10,   200] loss: 0.243\n",
      "[10,   250] loss: 0.206\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "nepoch = 10  # number of epochs\n",
    "print_num = 50\n",
    "for epoch in range(nepoch):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs\n",
    "        inputs, labels = data\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % print_num == (print_num-1):    # print every 50 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / print_num))\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll try out a couple of test samples just for visual kicks. First load them up and take a look at the true labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataiter = iter(testloader)\n",
    "images, labels = dataiter.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GroundTruth:   FRII  FRII\n"
     ]
    }
   ],
   "source": [
    "# print images\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "print('GroundTruth: ', ' '.join('%5s' % classes[labels[j]] for j in range(batch_size_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then see what the network predicts that they are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = net(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted:   FRII  FRII\n"
     ]
    }
   ],
   "source": [
    "_, predicted = torch.max(outputs, 1)\n",
    "print('Predicted: ', ' '.join('%5s' % classes[predicted[j]] for j in range(batch_size_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now calculate the overall accuracy of the network on **all** the test images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 50 test images: 78 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the 50 test images: %d %%' % (100 * correct / total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a imbalanced dataset, so let's take a look at the accuracy for individual classes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_correct = list(0. for i in range(10))\n",
    "class_total = list(0. for i in range(10))\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        c = (predicted == labels).squeeze()\n",
    "        for i in range(batch_size_test):\n",
    "            label = labels[i]\n",
    "            class_correct[label] += c[i].item()\n",
    "            class_total[label] += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of   FRI : 86 %\n",
      "Accuracy of  FRII : 71 %\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(classes)):\n",
    "    print('Accuracy of %5s : %2d %%' % (classes[i], 100 * class_correct[i] / class_total[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
